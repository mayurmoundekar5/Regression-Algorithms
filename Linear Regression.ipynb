{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"F:\\\\PROGRAMMING\\\\Python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F:\\\\PROGRAMMING\\\\Python'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "wcat=pd.read_csv(\"wc.at.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Waist</th>\n",
       "      <th>AT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>74.75</td>\n",
       "      <td>25.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72.60</td>\n",
       "      <td>25.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81.80</td>\n",
       "      <td>42.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83.95</td>\n",
       "      <td>42.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74.65</td>\n",
       "      <td>29.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>71.85</td>\n",
       "      <td>21.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>80.90</td>\n",
       "      <td>29.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>83.40</td>\n",
       "      <td>32.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>63.50</td>\n",
       "      <td>11.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>73.20</td>\n",
       "      <td>32.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>71.90</td>\n",
       "      <td>28.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>75.00</td>\n",
       "      <td>43.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>73.10</td>\n",
       "      <td>38.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>79.00</td>\n",
       "      <td>42.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>77.00</td>\n",
       "      <td>30.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>68.85</td>\n",
       "      <td>55.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>75.95</td>\n",
       "      <td>43.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>74.15</td>\n",
       "      <td>33.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>73.80</td>\n",
       "      <td>43.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>75.90</td>\n",
       "      <td>29.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>76.85</td>\n",
       "      <td>36.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>80.90</td>\n",
       "      <td>40.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>79.90</td>\n",
       "      <td>35.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>89.20</td>\n",
       "      <td>60.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>82.00</td>\n",
       "      <td>45.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>92.00</td>\n",
       "      <td>70.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>86.60</td>\n",
       "      <td>83.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>80.50</td>\n",
       "      <td>84.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>86.00</td>\n",
       "      <td>78.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>82.50</td>\n",
       "      <td>64.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>109.00</td>\n",
       "      <td>192.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>103.50</td>\n",
       "      <td>132.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>110.00</td>\n",
       "      <td>126.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>110.00</td>\n",
       "      <td>153.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>112.00</td>\n",
       "      <td>158.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>108.50</td>\n",
       "      <td>183.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>104.00</td>\n",
       "      <td>184.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>111.00</td>\n",
       "      <td>121.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>108.50</td>\n",
       "      <td>159.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>121.00</td>\n",
       "      <td>245.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>109.00</td>\n",
       "      <td>137.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>97.50</td>\n",
       "      <td>165.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>105.50</td>\n",
       "      <td>152.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>98.00</td>\n",
       "      <td>181.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>94.50</td>\n",
       "      <td>80.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>97.00</td>\n",
       "      <td>137.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>105.00</td>\n",
       "      <td>125.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>106.00</td>\n",
       "      <td>241.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>99.00</td>\n",
       "      <td>134.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>91.00</td>\n",
       "      <td>150.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>102.50</td>\n",
       "      <td>198.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>106.00</td>\n",
       "      <td>151.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>109.10</td>\n",
       "      <td>229.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>115.00</td>\n",
       "      <td>253.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>101.00</td>\n",
       "      <td>188.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>100.10</td>\n",
       "      <td>124.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>93.30</td>\n",
       "      <td>62.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>101.80</td>\n",
       "      <td>133.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>107.90</td>\n",
       "      <td>208.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>108.50</td>\n",
       "      <td>208.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Waist      AT\n",
       "0     74.75   25.72\n",
       "1     72.60   25.89\n",
       "2     81.80   42.60\n",
       "3     83.95   42.80\n",
       "4     74.65   29.84\n",
       "5     71.85   21.68\n",
       "6     80.90   29.08\n",
       "7     83.40   32.98\n",
       "8     63.50   11.44\n",
       "9     73.20   32.22\n",
       "10    71.90   28.32\n",
       "11    75.00   43.86\n",
       "12    73.10   38.21\n",
       "13    79.00   42.48\n",
       "14    77.00   30.96\n",
       "15    68.85   55.78\n",
       "16    75.95   43.78\n",
       "17    74.15   33.41\n",
       "18    73.80   43.35\n",
       "19    75.90   29.31\n",
       "20    76.85   36.60\n",
       "21    80.90   40.25\n",
       "22    79.90   35.43\n",
       "23    89.20   60.09\n",
       "24    82.00   45.84\n",
       "25    92.00   70.40\n",
       "26    86.60   83.45\n",
       "27    80.50   84.30\n",
       "28    86.00   78.89\n",
       "29    82.50   64.75\n",
       "..      ...     ...\n",
       "79   109.00  192.00\n",
       "80   103.50  132.00\n",
       "81   110.00  126.00\n",
       "82   110.00  153.00\n",
       "83   112.00  158.00\n",
       "84   108.50  183.00\n",
       "85   104.00  184.00\n",
       "86   111.00  121.00\n",
       "87   108.50  159.00\n",
       "88   121.00  245.00\n",
       "89   109.00  137.00\n",
       "90    97.50  165.00\n",
       "91   105.50  152.00\n",
       "92    98.00  181.00\n",
       "93    94.50   80.95\n",
       "94    97.00  137.00\n",
       "95   105.00  125.00\n",
       "96   106.00  241.00\n",
       "97    99.00  134.00\n",
       "98    91.00  150.00\n",
       "99   102.50  198.00\n",
       "100  106.00  151.00\n",
       "101  109.10  229.00\n",
       "102  115.00  253.00\n",
       "103  101.00  188.00\n",
       "104  100.10  124.00\n",
       "105   93.30   62.20\n",
       "106  101.80  133.00\n",
       "107  107.90  208.00\n",
       "108  108.50  208.00\n",
       "\n",
       "[109 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wcat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x19528224518>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(x=wcat['Waist'],y=wcat['AT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.81855781],\n",
       "       [0.81855781, 1.        ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(x=wcat['Waist'],y=wcat['AT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "model=smf.ols('AT~Waist',data=wcat).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept   -215.981488\n",
       "Waist          3.458859\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>AT</td>        <th>  R-squared:         </th> <td>   0.670</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.667</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   217.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 24 Sep 2019</td> <th>  Prob (F-statistic):</th> <td>1.62e-27</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:13:52</td>     <th>  Log-Likelihood:    </th> <td> -534.99</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   109</td>      <th>  AIC:               </th> <td>   1074.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   107</td>      <th>  BIC:               </th> <td>   1079.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td> -215.9815</td> <td>   21.796</td> <td>   -9.909</td> <td> 0.000</td> <td> -259.190</td> <td> -172.773</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Waist</th>     <td>    3.4589</td> <td>    0.235</td> <td>   14.740</td> <td> 0.000</td> <td>    2.994</td> <td>    3.924</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 3.960</td> <th>  Durbin-Watson:     </th> <td>   1.560</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.138</td> <th>  Jarque-Bera (JB):  </th> <td>   4.596</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.104</td> <th>  Prob(JB):          </th> <td>   0.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.984</td> <th>  Cond. No.          </th> <td>    639.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     AT   R-squared:                       0.670\n",
       "Model:                            OLS   Adj. R-squared:                  0.667\n",
       "Method:                 Least Squares   F-statistic:                     217.3\n",
       "Date:                Tue, 24 Sep 2019   Prob (F-statistic):           1.62e-27\n",
       "Time:                        12:13:52   Log-Likelihood:                -534.99\n",
       "No. Observations:                 109   AIC:                             1074.\n",
       "Df Residuals:                     107   BIC:                             1079.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept   -215.9815     21.796     -9.909      0.000    -259.190    -172.773\n",
       "Waist          3.4589      0.235     14.740      0.000       2.994       3.924\n",
       "==============================================================================\n",
       "Omnibus:                        3.960   Durbin-Watson:                   1.560\n",
       "Prob(Omnibus):                  0.138   Jarque-Bera (JB):                4.596\n",
       "Skew:                           0.104   Prob(JB):                        0.100\n",
       "Kurtosis:                       3.984   Cond. No.                         639.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    0           1\n",
      "Intercept -259.190053 -172.772923\n",
      "Waist        2.993689    3.924030\n"
     ]
    }
   ],
   "source": [
    "print(model.conf_int(0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       42.568252\n",
       "1       35.131704\n",
       "2       66.953210\n",
       "3       74.389758\n",
       "4       42.222366\n",
       "5       32.537559\n",
       "6       63.840237\n",
       "7       72.487385\n",
       "8        3.656083\n",
       "9       37.207020\n",
       "10      32.710502\n",
       "11      43.432966\n",
       "12      36.861134\n",
       "13      57.268404\n",
       "14      50.350685\n",
       "15      22.160981\n",
       "16      46.718883\n",
       "17      40.492936\n",
       "18      39.282335\n",
       "19      46.545940\n",
       "20      49.831856\n",
       "21      63.840237\n",
       "22      60.381377\n",
       "23      92.548770\n",
       "24      67.644982\n",
       "25     102.233576\n",
       "26      83.555735\n",
       "27      62.456693\n",
       "28      81.480420\n",
       "29      69.374412\n",
       "          ...    \n",
       "79     161.034186\n",
       "80     142.010459\n",
       "81     164.493045\n",
       "82     164.493045\n",
       "83     171.410764\n",
       "84     159.304756\n",
       "85     143.739889\n",
       "86     167.951905\n",
       "87     159.304756\n",
       "88     202.540498\n",
       "89     161.034186\n",
       "90     121.257303\n",
       "91     148.928178\n",
       "92     122.986732\n",
       "93     110.880725\n",
       "94     119.527873\n",
       "95     147.198748\n",
       "96     150.657608\n",
       "97     126.445592\n",
       "98      98.774717\n",
       "99     138.551600\n",
       "100    150.657608\n",
       "101    161.380072\n",
       "102    181.787342\n",
       "103    133.363311\n",
       "104    130.250337\n",
       "105    106.730093\n",
       "106    136.130398\n",
       "107    157.229440\n",
       "108    159.304756\n",
       "Length: 109, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(pd.DataFrame(wcat['Waist']))\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>AT</td>        <th>  R-squared:         </th> <td>   0.675</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.672</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   222.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 24 Sep 2019</td> <th>  Prob (F-statistic):</th> <td>6.80e-28</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:21:38</td>     <th>  Log-Likelihood:    </th> <td> -534.11</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   109</td>      <th>  AIC:               </th> <td>   1072.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   107</td>      <th>  BIC:               </th> <td>   1078.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>     <td>-1328.3420</td> <td>   95.923</td> <td>  -13.848</td> <td> 0.000</td> <td>-1518.498</td> <td>-1138.186</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>np.log(Waist)</th> <td>  317.1356</td> <td>   21.258</td> <td>   14.918</td> <td> 0.000</td> <td>  274.994</td> <td>  359.277</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 3.317</td> <th>  Durbin-Watson:     </th> <td>   1.599</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.190</td> <th>  Jarque-Bera (JB):  </th> <td>   2.908</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.235</td> <th>  Prob(JB):          </th> <td>   0.234</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.647</td> <th>  Cond. No.          </th> <td>    145.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     AT   R-squared:                       0.675\n",
       "Model:                            OLS   Adj. R-squared:                  0.672\n",
       "Method:                 Least Squares   F-statistic:                     222.6\n",
       "Date:                Tue, 24 Sep 2019   Prob (F-statistic):           6.80e-28\n",
       "Time:                        12:21:38   Log-Likelihood:                -534.11\n",
       "No. Observations:                 109   AIC:                             1072.\n",
       "Df Residuals:                     107   BIC:                             1078.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=================================================================================\n",
       "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------\n",
       "Intercept     -1328.3420     95.923    -13.848      0.000   -1518.498   -1138.186\n",
       "np.log(Waist)   317.1356     21.258     14.918      0.000     274.994     359.277\n",
       "==============================================================================\n",
       "Omnibus:                        3.317   Durbin-Watson:                   1.599\n",
       "Prob(Omnibus):                  0.190   Jarque-Bera (JB):                2.908\n",
       "Skew:                           0.235   Prob(JB):                        0.234\n",
       "Kurtosis:                       3.647   Cond. No.                         145.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = smf.ols('AT~np.log(Waist)',data=wcat).fit()\n",
    "model2.params\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       39.828156\n",
       "1       30.572779\n",
       "2       68.410960\n",
       "3       76.638769\n",
       "4       39.403610\n",
       "5       27.279545\n",
       "6       64.902356\n",
       "7       74.554213\n",
       "8      -11.899606\n",
       "9       33.182963\n",
       "10      27.500161\n",
       "11      40.887040\n",
       "12      32.749422\n",
       "13      57.365321\n",
       "14      49.233194\n",
       "15      13.753591\n",
       "16      44.878862\n",
       "17      37.272314\n",
       "18      35.771839\n",
       "19      44.670014\n",
       "20      48.614795\n",
       "21      64.902356\n",
       "22      60.957833\n",
       "23      95.876103\n",
       "24      69.185406\n",
       "25     105.677983\n",
       "26      86.494845\n",
       "27      63.330429\n",
       "28      84.289954\n",
       "29      71.113288\n",
       "          ...    \n",
       "79     159.451269\n",
       "80     143.031172\n",
       "81     162.347504\n",
       "82     162.347504\n",
       "83     168.061813\n",
       "84     157.993171\n",
       "85     144.559539\n",
       "86     165.217529\n",
       "87     157.993171\n",
       "88     192.573752\n",
       "89     159.451269\n",
       "90     124.092079\n",
       "91     149.100938\n",
       "92     125.714259\n",
       "93     114.180786\n",
       "94     122.461558\n",
       "95     147.594352\n",
       "96     150.600399\n",
       "97     128.933937\n",
       "98     102.211986\n",
       "99     139.952162\n",
       "100    150.600399\n",
       "101    159.742085\n",
       "102    176.444739\n",
       "103    135.276860\n",
       "104    132.438233\n",
       "105    110.127880\n",
       "106    137.778929\n",
       "107    156.234559\n",
       "108    157.993171\n",
       "Length: 109, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2 = model2.predict(pd.DataFrame(wcat['Waist']))\n",
    "pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
